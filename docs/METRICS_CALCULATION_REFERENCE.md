# Metrics Calculation Reference

**Project**: ATC Hallucination Detection System  
**Date**: October 9, 2025  
**Purpose**: Comprehensive documentation of how each performance metric is calculated

---

## Table of Contents

1. [Detection Metrics (Confusion Matrix)](#detection-metrics-confusion-matrix)
2. [Detection Performance Metrics](#detection-performance-metrics)
3. [Safety Metrics](#safety-metrics)
4. [Alert Quality Metrics](#alert-quality-metrics)
5. [Path Efficiency Metrics](#path-efficiency-metrics)
6. [Advanced Behavioral Metrics](#advanced-behavioral-metrics)
7. [Reward Metrics](#reward-metrics)
8. [Data Flow and Dependencies](#data-flow-and-dependencies)

---

## Detection Metrics (Confusion Matrix)

### 1. `tp` (True Positives)
**Definition**: Number of conflict windows correctly detected by the policy.

**Calculation**:
```python
# From HallucinationDetector.compute()
TP = len(matches)  # Number of matched (ground_truth, alert) window pairs
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:906`

**Inputs**:
- `G`: List of ground truth conflict windows (time intervals)
- `A`: List of alert windows (time intervals)
- `matches`: Pairs of (g_idx, a_idx) where IoU >= threshold (0.1)

**Dependencies**:
1. **Ground Truth Windows (G)**: Generated by `_ground_truth_series()` using TCPA/DCPA calculations
   - TCPA (Time to Closest Point of Approach)
   - DCPA (Distance at Closest Point of Approach)
   - Threshold: `sep_nm = 5.0` nautical miles
   - Time horizon: `horizon_s = 120.0` seconds
   
2. **Alert Windows (A)**: Generated by `_alerts_from_actions()` using action magnitude
   - Heading threshold: `theta_min_deg = 3.0` degrees
   - Speed threshold: `v_min_kt = 5.0` knots
   
3. **IoU Matching**: Windows matched using `_match_windows()` with IoU threshold = 0.1

**Method**:
- Ground truth conflicts detected when predicted DCPA < 5.0 NM within 120s horizon
- Alerts detected when action magnitude exceeds thresholds AND threat exists
- Windows expanded: ±30s for ground truth, ±10s for alerts
- IoU (Intersection over Union) matching ensures temporal overlap

---

### 2. `fp` (False Positives)
**Definition**: Number of alert windows that don't correspond to actual conflicts.

**Calculation**:
```python
# From HallucinationDetector.compute()
FP = len(A) - len(used_A)  # Alerts not matched to any ground truth
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:907`

**Inputs**:
- `A`: All alert windows detected from actions
- `used_A`: Set of alert indices that were matched to ground truth

**Interpretation**: "Ghost conflicts" - policy reacts when no conflict exists

---

### 3. `fn` (False Negatives)
**Definition**: Number of ground truth conflict windows missed by the policy.

**Calculation**:
```python
# From HallucinationDetector.compute()
FN = len(G) - TP  # Ground truth conflicts without matching alerts
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:906`

**Inputs**:
- `G`: All ground truth conflict windows
- `TP`: Number of matched windows

**Interpretation**: "Missed conflicts" - policy fails to react to actual conflicts

---

### 4. `tn` (True Negatives)
**Definition**: Number of timesteps with no conflict and no alert (correctly inactive).

**Calculation**:
```python
# From HallucinationDetector.compute()
TN_steps = int(np.sum(~g & ~a))  # Timesteps where both are False
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:908`

**Inputs**:
- `g`: Boolean array of ground truth conflict flags per timestep
- `a`: Boolean array of alert flags per timestep

**Note**: Unlike TP/FP/FN which count events, TN counts timesteps for computational reasons

---

## Detection Performance Metrics

### 5. `precision`
**Definition**: Fraction of alerts that correspond to actual conflicts.

**Calculation**:
```python
precision = TP / max(1, TP + FP)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:835`

**Range**: [0.0, 1.0]  
**Interpretation**: High precision means few false alarms

---

### 6. `recall`
**Definition**: Fraction of actual conflicts that were detected.

**Calculation**:
```python
recall = TP / max(1, TP + FN)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:836`

**Range**: [0.0, 1.0]  
**Interpretation**: High recall means few missed conflicts

---

### 7. `f1_score`
**Definition**: Harmonic mean of precision and recall.

**Calculation**:
```python
f1_score = 2 * precision * recall / max(1e-9, precision + recall)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:837`

**Range**: [0.0, 1.0]  
**Interpretation**: Balanced metric combining precision and recall

---

### 8. `ghost_conflict`
**Definition**: Legacy false alarm rate (FP rate in safe conditions).

**Calculation**:
```python
ghost_conflict = FP / max(1, FP + TN_steps)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:916`

**Range**: [0.0, 1.0]  
**Interpretation**: Probability of false alert when no conflict exists

---

### 9. `missed_conflict`
**Definition**: Legacy miss rate (FN rate in conflict conditions).

**Calculation**:
```python
missed_conflict = FN / max(1, FN + TP)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:917`

**Range**: [0.0, 1.0]  
**Interpretation**: Probability of missing a conflict when one exists

---

## Safety Metrics

### 10. `min_separation_nm`
**Definition**: Minimum horizontal separation between any aircraft pair during episode.

**Calculation**:
```python
# From HallucinationDetector._detect_los_events()
for t in range(T):
    for i, j in aircraft_pairs:
        sep_nm = haversine_nm(lat_i, lon_i, lat_j, lon_j)
        min_separation = min(min_separation, sep_nm)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:197-199`

**Unit**: Nautical miles  
**Critical Threshold**: 5.0 NM (standard separation minimum)

**Note**: Also returned as `min_CPA_nm` (minimum Closest Point of Approach) from ground truth series

---

### 11. `num_los_events`
**Definition**: Count of Loss of Separation events (continuous periods below threshold).

**Calculation**:
```python
# From HallucinationDetector._detect_los_events()
los_events = []
current_los_start = None

for t in range(T):
    if any_pair_below_threshold:
        if current_los_start is None:
            current_los_start = t
            los_events.append({'start_time': t, ...})
    else:
        if current_los_start is not None:
            los_events[-1]['end_time'] = t - 1
            current_los_start = None

num_los_events = len(los_events)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:183-226`

**Method**: Continuous tracking with event start/end detection

---

### 12. `total_los_duration`
**Definition**: Total timesteps spent in Loss of Separation across all events.

**Calculation**:
```python
# From HallucinationDetector._detect_los_events()
total_los_duration = 0
for event in los_events:
    total_los_duration += event['duration']  # end_time - start_time
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:220-226`

**Unit**: Timesteps (10 seconds per step)

---

### 13. `num_conflict_steps`
**Definition**: Number of timesteps where TCPA/DCPA predicts future violation.

**Calculation**:
```python
# From HallucinationDetector._ground_truth_series()
g = np.zeros(T, dtype=bool)
for t in range(T):
    for aircraft_pair in active_pairs:
        tcpa, dcpa = compute_tcpa_dcpa_nm(...)
        if dcpa < sep_nm:
            g[t] = True

num_conflict_steps = int(g.sum())
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:504-508`

**Method**: Forward-looking conflict prediction using relative velocities

---

## Alert Quality Metrics

### 14. `alert_duty_cycle`
**Definition**: Fraction of time the system is in alert state.

**Calculation**:
```python
alert_duty_cycle = float(np.mean(a))  # a is boolean array of alerts
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:839`

**Range**: [0.0, 1.0]  
**Interpretation**: Operator workload indicator

---

### 15. `alerts_per_min`
**Definition**: Rate of alerts per minute of flight time.

**Calculation Method 1** (from CSV trajectory):
```python
# From intrashift_tester.py:1342
episode_time_s = timestamps[-1] - timestamps[0]
alerts_per_min = (total_alert_time_s / max(1.0, episode_time_s / 60.0))
```

**Calculation Method 2** (from alert steps):
```python
# From intershift_matrix.py:450
alert_steps = count_alert_timesteps()
alerts_per_min = float(alert_steps * 6.0)  # 6 = 60s / 10s per step
```

**Sources**:
- `src/testing/intrashift_tester.py:1342`
- `src/testing/intershift_matrix.py:450`

**Unit**: Alerts per minute

---

### 16. `total_alert_time_s`
**Definition**: Total duration of all alert periods in seconds.

**Calculation**:
```python
# From HallucinationDetector.compute()
total_alert_time_s = float(np.sum(a)) * self.action_period_s
# where action_period_s = 10.0 (timestep duration)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:840`

**Unit**: Seconds

---

### 17. `avg_lead_time_s`
**Definition**: Average time between alert onset and predicted conflict.

**Calculation**:
```python
# From HallucinationDetector.compute()
lead_times = []
for g_idx, a_idx in matches:
    g_start, _ = G[g_idx]  # Ground truth conflict start
    a_start, _ = A[a_idx]  # Alert start
    lead_time_s = (g_start - a_start) * action_period_s
    lead_times.append(lead_time_s)

avg_lead_time = float(np.mean(lead_times)) if lead_times else 0.0
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:849-857`

**Unit**: Seconds  
**Interpretation**: Positive values indicate early alerts; negative indicates late detection

---

## Path Efficiency Metrics

### 18. `flight_time_s`
**Definition**: Total episode duration from start to end.

**Calculation**:
```python
# From HallucinationDetector._calculate_efficiency_metrics()
timestamps = trajectory.get("timestamps", [])
flight_time = timestamps[-1] - timestamps[0] if len(timestamps) > 1 else 0.0
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:326`

**Unit**: Seconds  
**Typical Range**: 0-600 seconds (typical episode: ~300s)

---

### 19. `total_path_length_nm`
**Definition**: Sum of actual flight path lengths for all agents.

**Calculation**:
```python
# From HallucinationDetector._calculate_efficiency_metrics()
agent_path_lengths = {}
for aid in all_agents:
    pts = [step[aid] for step in pos_seq if aid in step]
    L = sum(haversine_nm(*pts[i-1], *pts[i]) for i in range(1, len(pts)))
    agent_path_lengths[aid] = L

total_path_length = sum(agent_path_lengths.values())
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:272-276`

**Unit**: Nautical miles  
**Method**: Sequential point-to-point haversine distance summation

---

### 20. `path_efficiency`
**Definition**: Ratio of expected time to actual flight time (time-based efficiency).

**Calculation**:
```python
# From HallucinationDetector._calculate_efficiency_metrics()
expected_time = 300.0  # seconds, based on typical scenario duration
path_efficiency = min(1.0, expected_time / max(1.0, flight_time))
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:330-331`

**Range**: [0.0, 1.0]  
**Interpretation**: 1.0 = optimal time; <1.0 = took longer than expected

---

### 21. `waypoint_reached_ratio`
**Definition**: Fraction of agents that successfully reached their assigned waypoints.

**Calculation**:
```python
# From HallucinationDetector._calculate_efficiency_metrics()
waypoints_reached = 0
total_agents = len(all_agents)

for aid in all_agents:
    # Multiple detection methods in priority order:
    # 1. CSV waypoint completion data (preferred)
    if csv_waypoint_completion.get(aid) > 0:
        waypoints_reached += 1
    # 2. Waypoint status metadata
    elif waypoint_status[aid].get(final_timestep, False):
        waypoints_reached += 1
    # 3. Distance-based (legacy): within 1.0 NM
    elif final_dist_to_waypoint <= 1.0:
        waypoints_reached += 1

waypoint_reached_ratio = waypoints_reached / max(1, total_agents)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:275-315`

**Range**: [0.0, 1.0]  
**Threshold**: 1.0 NM (WAYPOINT_THRESHOLD_NM)

---

### 22. `total_extra_path_nm`
**Definition**: Sum of additional distance traveled beyond direct routes for all agents.

**Calculation**:
```python
# From HallucinationDetector._calculate_efficiency_metrics()
agent_extra_nm = {}
for aid in all_agents:
    if waypoints.get(aid) and pts:
        wlat, wlon = waypoints[aid]["lat"], waypoints[aid]["lon"]
        direct_nm = haversine_nm(pts[0][0], pts[0][1], wlat, wlon)
        actual_nm = agent_path_lengths[aid]
        extra_nm = max(0.0, actual_nm - direct_nm)
        agent_extra_nm[aid] = extra_nm

total_extra_nm = sum(agent_extra_nm.values())
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:317-322`

**Unit**: Nautical miles  
**Interpretation**: Deviation cost due to conflict avoidance maneuvers

---

### 23. `avg_extra_path_nm`
**Definition**: Mean additional distance per agent beyond direct route.

**Calculation**:
```python
avg_extra_nm = total_extra_nm / max(1, len(agent_extra_nm))
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:325`

**Unit**: Nautical miles

---

### 24. `avg_extra_path_ratio`
**Definition**: Mean fractional increase in path length (1.0 = 100% longer than direct).

**Calculation**:
```python
# From HallucinationDetector._calculate_efficiency_metrics()
agent_extra_ratio = {}
for aid in all_agents:
    if waypoints.get(aid):
        actual_nm = agent_path_lengths[aid]
        direct_nm = haversine_nm(start_pos, waypoint)
        ratio = (actual_nm / max(1e-6, direct_nm)) - 1.0
        agent_extra_ratio[aid] = ratio

avg_extra_ratio = sum(agent_extra_ratio.values()) / max(1, len(agent_extra_ratio))
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:318-326`

**Range**: [0.0, ∞)  
**Example**: 0.25 = 25% longer than direct route

---

## Advanced Behavioral Metrics

### 25. `num_interventions`
**Definition**: Total count of timesteps where any agent's action exceeded thresholds.

**Calculation**:
```python
# From HallucinationDetector.compute()
num_interventions_total = 0
for t in range(T):
    has_intervention = False
    for aid, action in actions_seq[t].items():
        hdg_delta = abs(action[0])
        spd_delta = abs(action[1])
        
        if hdg_delta >= theta_min_deg or spd_delta >= v_min_kt:
            has_intervention = True
            break
    
    if has_intervention:
        num_interventions_total += 1
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:824-833`

**Thresholds**:
- Heading: 3.0 degrees
- Speed: 5.0 knots

---

### 26. `num_interventions_matched`
**Definition**: Interventions that coincided with actual conflicts (TP scenario).

**Calculation**:
```python
# From HallucinationDetector.compute()
num_interventions_matched = 0
for t in intervention_steps:
    if g[t] and a[t]:  # Both ground truth and alert active
        num_interventions_matched += 1
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:820-832`

**Interpretation**: Correctly timed conflict avoidance actions

---

### 27. `num_interventions_false`
**Definition**: Interventions that did NOT match actual conflicts (FP/FN scenario).

**Calculation**:
```python
num_interventions_false = 0
for t in intervention_steps:
    if not (g[t] and a[t]):  # Either FP or FN
        num_interventions_false += 1
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:820-832`

**Interpretation**: Wasted or late conflict avoidance effort

---

### 28. `resolution_fail_rate`
**Definition**: Fraction of detected conflicts that failed to achieve post-conflict separation.

**Calculation**:
```python
# From HallucinationDetector._resolution_cm()
tp_res = 0  # Conflicts resolved (achieved post-conflict separation)
fn_res = 0  # Conflicts unresolved (failed post-conflict separation)

for g_idx, a_idx in matches:
    g_start, g_end = G[g_idx]
    check_start = g_end
    check_end = min(T, g_end + window_steps)  # window_s=60s => ~6 steps
    
    resolution_window = pos_seq[check_start:check_end]
    min_hmd = _min_hmd_window(resolution_window)
    
    if min_hmd > sep_nm:
        tp_res += 1  # Resolved
    else:
        fn_res += 1  # Failed

# In compute():
den_res = tp_res + fn_res
resolution_fail_rate = float(fn_res / den_res) if den_res > 0 else float("nan")
```

**Sources**:
- `src/analysis/hallucination_detector_enhanced.py:608-668`
- `src/analysis/hallucination_detector_enhanced.py:880-882`

**Range**: [0.0, 1.0] or NaN (if no conflicts to judge)  
**Interpretation**: Lower is better; 0.0 = all conflicts cleanly resolved

---

### 29. `los_failure_rate`
**Definition**: Fraction of conflicts where Loss of Separation occurred during conflict window.

**Calculation**:
```python
# From HallucinationDetector._resolution_cm()
tp_los = 0  # Conflicts that avoided LoS during window
fn_los = 0  # Conflicts with LoS during window

for g_idx, a_idx in matches:
    g_start, g_end = G[g_idx]
    conflict_window = pos_seq[g_start:g_end]
    min_sep_during_conflict = _min_hmd_window(conflict_window)
    
    if min_sep_during_conflict < sep_nm:
        fn_los += 1  # LoS occurred
    else:
        tp_los += 1  # LoS avoided

# In compute():
den_los = tp_los + fn_los
los_failure_rate = float(fn_los / den_los) if den_los > 0 else float("nan")
```

**Sources**:
- `src/analysis/hallucination_detector_enhanced.py:620-635`
- `src/analysis/hallucination_detector_enhanced.py:886-888`

**Range**: [0.0, 1.0] or NaN  
**Interpretation**: Tactical safety measure; 0.0 = maintained separation throughout

---

### 30. `oscillation_rate`
**Definition**: Combined metric of command instability (sign-flip rate + total variation).

**Calculation**:
```python
# From HallucinationDetector.compute()

# Part 1: Sign-flip rate (direction reversals)
sign_flips = 0
active_transitions = 0
theta_h = 2.0  # Deadzone for heading (degrees)

for t in range(1, T):
    m0 = mean_heading_command[t-1]
    m1 = mean_heading_command[t]
    
    # Count as flip if both steps have significant opposite commands
    if abs(m0) >= theta_h and abs(m1) >= theta_h:
        if sign(m0) != sign(m1):
            sign_flips += 1
        active_transitions += 1

osc_rate_flips = float(sign_flips) / max(1, active_transitions)

# Part 2: Total variation rate (normalized jitter)
if len(hdg_series) > 1:
    tv_h = sum(abs(hdg_series[i] - hdg_series[i-1]) for i in range(1, len(hdg_series)))
    tv_h /= (18.0 * (len(hdg_series) - 1))  # Normalized by D_HEADING
else:
    tv_h = 0.0

if len(spd_series) > 1:
    tv_v = sum(abs(spd_series[i] - spd_series[i-1]) for i in range(1, len(spd_series)))
    tv_v /= (10.0 * (len(spd_series) - 1))  # Normalized by D_VELOCITY
else:
    tv_v = 0.0

# Combined metric
oscillation_rate = 0.5 * (osc_rate_flips + (tv_h + tv_v) / 2.0)
```

**Source**: `src/analysis/hallucination_detector_enhanced.py:860-899`

**Range**: [0.0, ~1.0]  
**Components**:
- Sign-flip rate: Frequency of command reversals
- Total variation: Normalized command jitter
**Interpretation**: Higher values indicate unstable, twitchy control behavior

---

## Reward Metrics

### 31. `reward_total`
**Definition**: Cumulative reward across all agents for entire episode.

**Calculation**:
```python
# Extraction from trajectory CSV
reward_total = df['reward'].sum()  # Sum across all timesteps and agents
```

**Sources**:
- `src/testing/intrashift_tester.py:1607`
- `src/testing/intershift_matrix.py:474`

**Per-timestep Reward Components** (from environment):
```python
# From marl_collision_env_minimal.py:769-852
r_total = (
    r_progress +           # Signed waypoint approach (+ve closer, -ve farther)
    r_drift +              # Improvement in heading alignment with waypoint
    r_violate_entry +      # One-time penalty on entering violation zone (-25)
    r_violate_step +       # Per-step severity penalty in violation zone
    act_cost +             # Action magnitude penalty (-0.01 per normalized unit)
    r_time +               # Time penalty per second (-0.0005 * 10s)
    r_reach +              # Waypoint completion bonus (+10.0 once)
    r_terminal +           # Episode-end penalty if waypoint not reached (-10.0)
    r_team                 # Team coordination PBRS shaping term
)
```

**Reward Component Details**:

1. **Progress Reward** (`r_progress`):
   ```python
   delta_nm = prev_waypoint_dist - current_waypoint_dist
   r_progress = (delta_nm * 1.852) * 0.04  # km * reward_per_km
   ```
   - Encourages waypoint approach
   - Coefficient: `progress_reward_per_km = 0.04`

2. **Drift Improvement** (`r_drift`):
   ```python
   drift_abs = |shortest_angle(heading, bearing_to_waypoint)|
   improve = max(0, (prev_drift - drift_abs) - deadzone)
   r_drift = 0.01 * improve  # gain * improvement
   ```
   - Rewards heading alignment improvements
   - Deadzone: 8.0 degrees (avoids penalizing small oscillations)

3. **Violation Entry** (`r_violate_entry`):
   ```python
   r_violate_entry = -25.0 if (not prev_in_violation and in_violation) else 0.0
   ```
   - One-time penalty when entering separation violation zone

4. **Violation Step** (`r_violate_step`):
   ```python
   if in_violation:
       depth = (sep_nm - current_sep) / sep_nm  # 0..1
       deep_boost = 1.0 + 1.5 * max(0, (1.0 - current_sep) / 1.0)
       r_violate_step = -1.0 * depth * deep_boost
   ```
   - Per-step penalty proportional to violation severity
   - Deep breach boost for distances <1.0 NM

5. **Action Cost** (`act_cost`):
   ```python
   act_cost = -0.01 * (abs(norm_hdg) + abs(norm_spd))
   ```
   - Penalizes large control actions
   - Encourages smooth, minimal interventions

6. **Time Penalty** (`r_time`):
   ```python
   r_time = -0.0005 * 10.0  # per_sec * timestep_duration
   ```
   - Encourages faster waypoint completion

7. **Reach Bonus** (`r_reach`):
   ```python
   r_reach = 10.0 if first_time_waypoint_reach else 0.0
   ```
   - One-time bonus for waypoint completion

8. **Terminal Penalty** (`r_terminal`):
   ```python
   r_terminal = -10.0 if (episode_end and not waypoint_reached) else 0.0
   ```
   - Penalizes incomplete missions

9. **Team Coordination** (`r_team`):
   ```python
   phi_now = sum_over_agents(min_separation_to_others)
   dphi = gamma * phi_now - phi_prev  # PBRS potential difference
   dphi_ema = (1 - alpha) * dphi_ema_prev + alpha * dphi
   dphi_shaped = clip(dphi_ema, -cap, cap) * anneal
   r_team = team_weight * responsibility_weight * dphi_shaped
   ```
   - Potential-Based Reward Shaping (PBRS) for team coordination
   - Parameters: weight=0.6, gamma=0.99, cap=0.05, ema=0.05

**Sources**:
- `src/environment/marl_collision_env_minimal.py:769-882`
- Training configuration: `src/training/train_frozen_scenario.py:230-246`

---

## Data Flow and Dependencies

### Trajectory Data Structure
All metrics are computed from episode trajectories with this structure:

```python
trajectory = {
    "positions": [                          # Per-timestep positions
        {"A1": (lat, lon), "A2": (lat, lon), ...},
        ...
    ],
    "actions": [                            # Per-timestep actions
        {"A1": [hdg_delta, spd_delta], ...},
        ...
    ],
    "timestamps": [0.0, 10.0, 20.0, ...],  # Simulation time in seconds
    "agents": {                             # Per-agent time series
        "A1": {
            "headings": [270.0, 268.5, ...],
            "speeds": [250.0, 245.0, ...]
        },
        ...
    },
    "waypoints": {                          # Target waypoints
        "A1": {"lat": 52.3, "lon": 4.8},
        ...
    },
    "waypoint_status": {                    # Completion tracking
        "A1": {0: False, 50: True, ...},
        ...
    },
    "scenario_metadata": {
        "test_id": "baseline_A1_seed42",
        "target_agent": "A1",
        "seed": 42,
        "num_agents": 2,
        "num_steps": 60
    }
}
```

### Calculation Pipeline

```
Episode Simulation
    ↓
Trajectory CSV (traj_XXXXX.csv)
    ↓
csv_to_trajectory() → trajectory dict
    ↓
HallucinationDetector.compute(trajectory)
    ↓
┌─────────────────────────────────────┐
│ 1. _ground_truth_series()          │ → g, min_cpa, num_conflict_steps
│    - TCPA/DCPA calculations         │
│    - Waypoint filtering             │
├─────────────────────────────────────┤
│ 2. _alerts_from_actions()          │ → a, alert_meta
│    - Action magnitude detection     │
│    - Intent-aware filtering         │
│    - Threat-aware gating            │
├─────────────────────────────────────┤
│ 3. _merge_runs()                    │ → G (ground truth windows)
│    - Expand ±30s                    │   A (alert windows)
│    - Merge consecutive timesteps    │
├─────────────────────────────────────┤
│ 4. _match_windows()                 │ → matches, used_A
│    - IoU threshold = 0.1            │
│    - Greedy matching                │
├─────────────────────────────────────┤
│ 5. Confusion Matrix                 │ → TP, FP, FN, TN
│    TP = len(matches)                │   precision, recall, f1
│    FP = len(A) - len(used_A)        │
│    FN = len(G) - TP                 │
├─────────────────────────────────────┤
│ 6. _resolution_cm()                 │ → resolution_fail_rate
│    - Post-conflict separation       │   los_failure_rate
│    - During-conflict LoS check      │
├─────────────────────────────────────┤
│ 7. _detect_los_events()             │ → num_los_events
│    - Continuous LoS tracking        │   total_los_duration
│    - Event start/end detection      │   min_separation_nm
├─────────────────────────────────────┤
│ 8. _calculate_efficiency_metrics() │ → path metrics
│    - Path length summation          │   waypoint completion
│    - Direct route comparison        │   efficiency ratios
├─────────────────────────────────────┤
│ 9. Oscillation analysis             │ → oscillation_rate
│    - Sign-flip rate                 │
│    - Total variation                │
└─────────────────────────────────────┘
    ↓
Combined metrics dictionary
    ↓
Episode summary CSV
    ↓
Aggregated analysis (mean, std, min, max per shift)
```

### Key Files and Functions

| Metric Category | Primary Source | Key Functions |
|----------------|----------------|---------------|
| Detection (TP/FP/FN/TN) | `hallucination_detector_enhanced.py` | `compute()`, `_match_windows()` |
| Precision/Recall/F1 | `hallucination_detector_enhanced.py` | `compute()` (lines 835-837) |
| Safety (LoS, separation) | `hallucination_detector_enhanced.py` | `_detect_los_events()`, `_ground_truth_series()` |
| Path efficiency | `hallucination_detector_enhanced.py` | `_calculate_efficiency_metrics()` |
| Resolution quality | `hallucination_detector_enhanced.py` | `_resolution_cm()` |
| Oscillation | `hallucination_detector_enhanced.py` | `compute()` (lines 860-899) |
| Reward | `marl_collision_env_minimal.py` | `step()` (lines 769-882) |
| CSV extraction | `intrashift_tester.py` | `extract_comprehensive_metrics_from_csv()` |
| Aggregation | `intrashift_tester.py` | `_create_targeted_analysis()` |

### Environment Configuration Dependencies

Critical parameters that affect metric calculations:

```python
env_config = {
    # Detection thresholds
    "neighbor_topk": 3,              # Top-K neighbors in observations
    "collision_nm": 3.0,             # Hard collision threshold
    "separation_nm": 5.0,            # Standard separation minimum
    
    # Time parameters
    "max_episode_steps": 150,        # Episode length (150 × 10s = 25 min)
    "action_delay_steps": 0,         # Action lag (usually 0)
    
    # Hallucination detector
    "enable_hallucination_detection": True,
    
    # Reward coefficients
    "progress_reward_per_km": 0.04,
    "violation_entry_penalty": -25.0,
    "violation_step_scale": -1.0,
    "deep_breach_nm": 1.0,
    "drift_improve_gain": 0.01,
    "drift_deadzone_deg": 8.0,
    "time_penalty_per_sec": -0.0005,
    "reach_reward": 10.0,
    "action_cost_per_unit": -0.01,
    "terminal_not_reached_penalty": -10.0,
    
    # Team coordination (PBRS)
    "team_coordination_weight": 0.6,
    "team_gamma": 0.99,
    "team_share_mode": "responsibility",
    "team_ema": 0.05,
    "team_cap": 0.05,
    "team_anneal": 1.0,
    "team_neighbor_threshold_km": 10.0,
}
```

### HallucinationDetector Configuration

```python
detector = HallucinationDetector(
    horizon_s=120.0,              # TCPA/DCPA prediction horizon
    action_thresh=(3.0, 5.0),     # (heading_deg, speed_kt) thresholds
    res_window_s=60.0,            # Post-conflict resolution window
    action_period_s=10.0,         # Timestep duration
    los_threshold_nm=5.0,         # Loss of separation threshold
    lag_pre_steps=1,              # Alert expansion before
    lag_post_steps=1,             # Alert expansion after
    debounce_n=2,                 # Minimum detections in window
    debounce_m=3,                 # Debounce window size
    iou_threshold=0.1             # Window matching threshold
)
```

---

## Summary Table

| Metric | Type | Source | Unit | Range/Typical |
|--------|------|--------|------|---------------|
| `tp` | Detection | Matched windows | count | 0-50 |
| `fp` | Detection | Unmatched alerts | count | 0-100 |
| `fn` | Detection | Unmatched conflicts | count | 0-50 |
| `tn` | Detection | Inactive timesteps | count | 0-150 |
| `precision` | Performance | TP/(TP+FP) | ratio | 0.0-1.0 |
| `recall` | Performance | TP/(TP+FN) | ratio | 0.0-1.0 |
| `f1_score` | Performance | 2PR/(P+R) | ratio | 0.0-1.0 |
| `ghost_conflict` | Legacy | FP/(FP+TN) | ratio | 0.0-1.0 |
| `missed_conflict` | Legacy | FN/(FN+TP) | ratio | 0.0-1.0 |
| `min_separation_nm` | Safety | Haversine min | NM | 0.0-200.0 |
| `num_los_events` | Safety | Event count | count | 0-20 |
| `total_los_duration` | Safety | Timestep sum | steps | 0-150 |
| `num_conflict_steps` | Safety | TCPA/DCPA sum | steps | 0-150 |
| `alert_duty_cycle` | Alert Quality | Mean(alerts) | ratio | 0.0-1.0 |
| `alerts_per_min` | Alert Quality | Alerts/minute | rate | 0-60 |
| `total_alert_time_s` | Alert Quality | Duration sum | seconds | 0-1500 |
| `avg_lead_time_s` | Alert Quality | Alert timing | seconds | -60 to +120 |
| `flight_time_s` | Efficiency | Time span | seconds | 0-600 |
| `total_path_length_nm` | Efficiency | Path sum | NM | 0-200 |
| `path_efficiency` | Efficiency | Time ratio | ratio | 0.0-1.0 |
| `waypoint_reached_ratio` | Efficiency | Completion | ratio | 0.0-1.0 |
| `total_extra_path_nm` | Efficiency | Deviation sum | NM | 0-100 |
| `avg_extra_path_nm` | Efficiency | Deviation mean | NM | 0-50 |
| `avg_extra_path_ratio` | Efficiency | Relative deviation | ratio | 0.0-2.0 |
| `num_interventions` | Behavior | Action count | count | 0-150 |
| `num_interventions_matched` | Behavior | Correct actions | count | 0-100 |
| `num_interventions_false` | Behavior | Incorrect actions | count | 0-100 |
| `resolution_fail_rate` | Advanced | fn_res/(tp_res+fn_res) | ratio | 0.0-1.0 or NaN |
| `los_failure_rate` | Advanced | fn_los/(tp_los+fn_los) | ratio | 0.0-1.0 or NaN |
| `oscillation_rate` | Advanced | Combined instability | ratio | 0.0-1.0 |
| `reward_total` | Reward | Sum(all rewards) | score | -∞ to +∞ |

---

## Notes

1. **NaN Values**: `resolution_fail_rate` and `los_failure_rate` return `float("nan")` when there are no matched conflicts to evaluate (denominator = 0). This distinguishes "no cases to judge" from "perfect performance (0.0)".

2. **Timestep vs Event Counting**: Most confusion matrix metrics count events (windows), but `tn` counts timesteps for computational efficiency.

3. **IoU Matching**: The 0.1 IoU threshold means windows need only 10% overlap to match, making the system robust to timing variations.

4. **Action Thresholds**: The 3°/5kt thresholds filter out normal navigation drift, focusing on deliberate conflict avoidance maneuvers.

5. **Reward Components**: The unified reward system balances safety (violation penalties), efficiency (progress rewards), and behavior quality (action costs, drift improvement).

6. **Team Coordination**: PBRS (Potential-Based Reward Shaping) adds a coordinated team term that improves multi-agent cooperation without affecting optimal policy.

---

**Last Updated**: October 9, 2025  
**Maintained By**: Development Team  
**Related Documents**: 
- `docs/graded_shift_ladder.md` - Distribution shift testing methodology
- `docs/crm_collision_risk_analysis.md` - Safety analysis framework
- `.github/copilot-instructions.md` - Project architecture overview
